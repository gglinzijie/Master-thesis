{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To unify the sampler, we borrow function from R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = int(10)\n",
    "nfold = int(5)\n",
    "nsample = int(240)\n",
    "cf=int(nsample/nfold)\n",
    "lf=nsample-cf\n",
    "import rpy2.robjects as robjects\n",
    "import numpy as np\n",
    "setseed = robjects.r['set.seed']\n",
    "sample = robjects.r['sample']\n",
    "sd = robjects.r[\"sd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Platform information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uname_result(system='Windows', node='LAPTOP-9BDORFP1', release='10', version='10.0.17134', machine='AMD64', processor='Intel64 Family 6 Model 158 Stepping 9, GenuineIntel')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.uname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13544685235067680755, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 78616985\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 6268415023482120726\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4 | packaged by conda-forge | (default, Dec 18 2017, 06:53:03) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pheno = pd.read_csv('./2017heteroPheno.csv')\n",
    "I = pd.read_table('./Hetero_realigned_cov10_filtered3.raw',sep=\"\\s+\").as_matrix()-1\n",
    "bcw=pheno.bcw.as_matrix()\n",
    "length=pheno.length.as_matrix()\n",
    "AccSum1=np.reshape(np.zeros(repeats*nfold),(nfold,repeats))\n",
    "AccSum2=np.copy(AccSum1);AccSum3=np.copy(AccSum1);AccSum4=np.copy(AccSum1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages for deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version of tensorflow_gpu: 1.4.0\n",
      "version of tensorflow_bakend_keras: 2.1.4\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import time\n",
    "print(\"version of tensorflow_gpu:\",tf.__version__)\n",
    "print(\"version of tensorflow_bakend_keras:\",keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#10-repeat-5-fold Cross validation as same as R\n",
    "for j in range(repeats):\n",
    "    setseed(100+3*(j+1)+1)\n",
    "    id =np.array(sample(robjects.IntVector(np.arange(1,(nsample+1)) %nfold)))\n",
    "    for i in range(nfold):\n",
    "        test = np.array(np.where(id==i)).reshape(cf)\n",
    "        train = np.array(np.where(id!=i)).reshape(lf)\n",
    "        #Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(200, activation='relu', input_dim=3928))\n",
    "        model.add(Dense(20, activation='relu'))\n",
    "        model.add(Dense(1)) \n",
    "        #Optimizer\n",
    "        model.compile(optimizer='Adam',loss='mse')\n",
    "        #Feed the data\n",
    "        model.fit(I[train,],bcw[train],epochs=35, batch_size=128)\n",
    "        #Prediction\n",
    "        pred = model.predict(I[test,],batch_size=None, verbose=0).reshape(cf)\n",
    "        pred1 = model.predict(I[train,],batch_size=None, verbose=0).reshape(lf)\n",
    "        #Accuracy\n",
    "        AccSum1[i,j] = pearsonr(pred,bcw[test])[0]\n",
    "        AccSum2[i,j] = pearsonr(pred1,bcw[train])[0]\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eplased time 414.90176010131836\n"
     ]
    }
   ],
   "source": [
    "print(\"eplased time\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.300227714854724 0.9741363391166052\n"
     ]
    }
   ],
   "source": [
    "#validate on test and train group\n",
    "print(np.mean(AccSum1),np.mean(AccSum2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='modelbasic.png',show_layer_names=True,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi task deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "rmsprop=optimizers.RMSprop(lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#10-repeat-5-fold Cross validation as same as R\n",
    "for j in range(repeats):\n",
    "    setseed(100+3*(j+1)+1)\n",
    "    id =np.array(sample(robjects.IntVector(np.arange(1,(nsample+1)) %nfold)))\n",
    "    for i in range(nfold):\n",
    "        test = np.array(np.where(id==i)).reshape(cf)\n",
    "        train = np.array(np.where(id!=i)).reshape(lf)\n",
    "        #Model\n",
    "        main_input = Input(shape=(3928,), name='main_input')\n",
    "        x = Dense(200, activation='relu')(main_input)\n",
    "\n",
    "\n",
    "        x1 = Dense(20, activation='relu')(x)\n",
    "        y1 = Dense(1,name='y1')(x1)\n",
    "\n",
    "        x2 = Dense(100, activation='relu')(x)\n",
    "        y2= Dense(1,name='y2')(x2)\n",
    "\n",
    "        model = Model(inputs=[main_input], outputs=[y1,y2])\n",
    "        #Compile\n",
    "        model.compile(optimizer=rmsprop,loss={'y1': 'mse','y2':'mse'},loss_weights={'y1': 1.,'y2': 0.2})\n",
    "        #Train\n",
    "        model.fit({'main_input': I[train,]},{'y1': bcw[train],'y2': length[train]},\n",
    "                      epochs=30, batch_size=128,callbacks=None)\n",
    "        #Accuracy\n",
    "        AccSum3[i,j] =pearsonr(model.predict(I[test,], batch_size=None, verbose=0)[0].reshape(cf),bcw[test])[0]\n",
    "        AccSum4[i,j] =pearsonr(model.predict(I[train,], batch_size=None, verbose=0)[0].reshape(lf),bcw[train])[0]\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eplased time 312.6359119415283\n"
     ]
    }
   ],
   "source": [
    "print(\"eplased time\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30666759049545633 0.9376196462345063\n"
     ]
    }
   ],
   "source": [
    "#validate on test and train\n",
    "print(np.mean(AccSum3),np.mean(AccSum4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png',show_layer_names=False,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result\n",
    "import pandas as pd\n",
    "seven_models_r = pd.read_excel(\"All_models_Acc.xlsx\")\n",
    "v1=pd.DataFrame(pd.DataFrame(AccSum1).values.flatten(),columns=[\"NN\"],index=range(1,51))\n",
    "v2=pd.DataFrame(pd.DataFrame(AccSum3).values.flatten(),columns=[\"MNN\"],index=range(1,51))\n",
    "pd.concat([seven_models_r,v1,v2],axis=1).to_excel('All_models_Acc.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
